
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction &#8212; Applying explainable machine learning to national stroke audit data to explore variation in decisions to use thrombolysis</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Outline" href="../xgb_with_feature_selection/outline.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Applying explainable machine learning to national stroke audit data to explore variation in decisions to use thrombolysis</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1 current">
  <a class="reference internal" href="#">
   Introduction
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../xgb_with_feature_selection/outline.html">
   Outline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../shap_worked_example.html">
   A simple worked example of Shap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xgb_with_feature_selection/01_xgb_combined_fit_feature_selection.html">
   XGBoost feature selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xgb_with_feature_selection/07_correlation.html">
   Check correlation between selected features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xgb_with_feature_selection/02_xgb_combined_fit_accuracy_key_features.html">
   Measuring accuracy of k-fold models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xgb_with_feature_selection/03_xgb_combined_shap_key_features.html">
   Explaining XGBoost model predictions with Shapley values
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xgb_with_feature_selection/04_compare_10k_cohort_key_features.html">
   A comparison of 10K cohort thrombolysis rates across hospitals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xgb_with_feature_selection/05_compare_benchmark_decisions_key_features.html">
   Compare local thrombolysis decisions with benchmark decisions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xgb_with_feature_selection/06_predict_differences_between_local_and_benchmark_key_features.html">
   Predicting differences between local and benchmark decisions
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/introduction/intro.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aims-of-this-study">
   Aims of this study
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-explainable-machine-learning">
   What is
   <em>
    Explainable Machine Learning
   </em>
   ?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods">
   Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-shapley-values">
     What are Shapley values?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-findings">
   Key findings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predicting-thrombolysis-use-with-an-xg-boost-model">
     Predicting thrombolysis use with an XG-Boost model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predicting-differences-in-thrombolysis-use-between-hospitals-with-an-xg-boost-model">
     Predicting
     <em>
      differences
     </em>
     in thrombolysis use between hospitals with an XG-Boost model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusions">
   Conclusions
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Introduction</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aims-of-this-study">
   Aims of this study
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-explainable-machine-learning">
   What is
   <em>
    Explainable Machine Learning
   </em>
   ?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods">
   Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-shapley-values">
     What are Shapley values?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-findings">
   Key findings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predicting-thrombolysis-use-with-an-xg-boost-model">
     Predicting thrombolysis use with an XG-Boost model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predicting-differences-in-thrombolysis-use-between-hospitals-with-an-xg-boost-model">
     Predicting
     <em>
      differences
     </em>
     in thrombolysis use between hospitals with an XG-Boost model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusions">
   Conclusions
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p><em>Applying explainable machine learning to national stroke audit data to explore variation in decisions to use thrombolysis</em>: Part of the NIHR <em>SAMueL</em> (Stroke Audit Machine Learning) project.</p>
<p>Kerry Pearn &amp; Michael Allen</p>
<blockquote class="epigraph">
<div><p>“Your decision to treat or not treat … That’s the difficult part. That’s the grey area where everyone does a different thing.”</p>
<p class="attribution">—Stroke Consultant during interviews for SAMueL</p>
</div></blockquote>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>Stroke is a common cause of adult disability. Most strokes (about four out of five) are caused by a blood clot in the brain. Expert opinion is that about one in five patients should receive clot-busting drugs to break up the blood clot that is causing their stroke, and this is the target set in the NHS long term plan. This clot-busting treatment is called <em>thrombolysis</em>. At the moment only about one in nine patients actually receive this treatment in the UK. There is a lot of variation between hospitals, which means that the same patient might receive different treatment in different hospitals.</p>
<p>In a previous project, <a class="reference external" href="https://samuel-book.github.io/samuel-1/introduction/intro.html">SAMueL-1</a>, we trained machine-learning models to predict whether any individual patient would receive thrombolysis in any hospital. This allows us to investigate what differences in treatment are likely to be due to differences between patients, and what differences in treatment are likely to be due to differences between hospitals rather differences in the patients each hospital sees.</p>
</div>
<div class="section" id="aims-of-this-study">
<h2>Aims of this study<a class="headerlink" href="#aims-of-this-study" title="Permalink to this headline">¶</a></h2>
<p>The aims of this study were 1) to apply <em>explainable machine learning</em> techniques to investigate the most significant features that drive decisions to use thrombolysis at different hospitals, and 2) to model and explain what are the the features that are most important in hospitals making <em>different</em> decisions about the same patient.</p>
</div>
<div class="section" id="what-is-explainable-machine-learning">
<h2>What is <em>Explainable Machine Learning</em>?<a class="headerlink" href="#what-is-explainable-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>Machine learning models generally learn from large sets of data - learning patterns between aspects of the data and some outcome of interest. In our use case the data contains a range of <em>features</em> about the patient, such as their age, sex, a breakdown of their stroke symptoms, etc. And the machine learning model learns the relationship between those features and the <em>target</em> that we would like to predict - that is whether the patient receives thrombolysis or not.</p>
<p>A high level diagram of our machine learning is shown in <a class="reference internal" href="#high-level-md"><span class="std std-numref">Figure 1</span></a>.</p>
<div class="figure align-default" id="high-level-md">
<a class="reference internal image-reference" href="../_images/ml_model_high_level.png"><img alt="../_images/ml_model_high_level.png" src="../_images/ml_model_high_level.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">A high level depiction of machine learning models trained to predict use of thrombolysis for any patient given 1) the hospital they attend, 2) patient and clinical information, and 3) pathway and process information.</span><a class="headerlink" href="#high-level-md" title="Permalink to this image">¶</a></p>
</div>
<p>There are many different types of machine learning (here we use one called <em>XG-Boost</em>), but all are making predictions based on similarities to what the model has seen before. Many machine learning models are what we call <em>black box</em> models - that is we give it some information, and it makes a prediction, but we don’t know <em>why</em> it made that particular prediction.</p>
<p><em>Explainable Machine Learning</em> seeks to be able to communicate why models make the prediction they do. We seek to understand, and communicate, the general patterns that the model is making (sometimes we call this <em>global explainability</em>), as well as why the model made the prediction it did for one particular patient (sometimes we call this <em>local explainability</em>). We also try to explain other important aspects about the model such as where the training data came from (and how representative is that data of where the model will be used in practice), and how a sure can we be of the model’s predictions - both generally and for any particular prediction.</p>
<p>In this project we are very much on a journey - discovering what different people would like to know about the model. Do patients, clinicians, and other machine learning researchers all want to know the same things, or different things? How can we tailor <em>explainable machine learning</em> output to different audience’s wishes?</p>
<p>(<em>Explainable machine learning</em> may also be known as <em>Explainable ML</em>, <em>Explainable artificial intelligence</em>, or <em>Explainable AI</em>).</p>
</div>
<div class="section" id="methods">
<h2>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h2>
<p>In this study we used a machine learning method called <em>XG-Boost</em> to predict decisions to give thrombolysis at each of 132 hospitals in England and Wales that deal with emergency stroke admissions.</p>
<p>In order to make the model easier to explain we found the most important features that would predict whether a patient received thrombolysis or not. We found that with 8 features we could get accuracy that was very close to using all available features. These 8 features were:</p>
<ul class="simple">
<li><p><em>S2BrainImagingTime_min</em>: Time from arrival at hospital to scan</p></li>
<li><p><em>S2StrokeType_Infarction</em>: Stroke type: clot (‘infarction’) or bleed (‘haemorrhage’)</p></li>
<li><p><em>S2NihssArrival</em>: Stroke severity (National Institutes of Health Stroke Scale; NIHSS) on arrival</p></li>
<li><p><em>S1OnsetTimeType_Precise</em>: Is stroke onset time known precisely (or estimated)</p></li>
<li><p><em>S2RankinBeforeStroke</em>: Disability level (modified Rankin Scale) <em>before</em> stroke</p></li>
<li><p><em>StrokeTeam</em>: Hospital ID</p></li>
<li><p><em>AFAnticoagulent_Yes</em>: Patient on anticoagulant therapy for atrial fibrillation</p></li>
<li><p><em>S1OnsetToArrival_min</em>: Time from stroke onset to arrival at hospital</p></li>
</ul>
<p>Note: The <a class="reference external" href="https://github.com/samuel-book/samuel_shap_paper_1">GitHub repository</a> also includes XG-Boost models using all available features.</p>
<p>In order to explain model predictions we turned to a method called Shapley values, which we describe below.</p>
<div class="section" id="what-are-shapley-values">
<h3>What are Shapley values?<a class="headerlink" href="#what-are-shapley-values" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Shapley values (or <em>Shap</em> values)are <em>‘the average expected marginal contribution of one player after all possible combinations have been considered’</em>.</p>
</div></blockquote>
<p>Or, imagine a pub quiz team with up to 3 people. Any number of people may actually turn up on the night:</p>
<ul class="simple">
<li><p>There are 8 possible combinations of players (including no-one turning up).</p></li>
<li><p>The Shapley value for any team member describes the average difference in score when a particular player is present or absent compared to the average of all combinations of players.</p></li>
</ul>
<p>The same principle may be applied in machine learning: How does any one feature (e.g. stroke severity, or age), on average, contribute to the prediction after considering all possible combinations of features? What difference does that feature make to the prediction?</p>
</div>
</div>
<div class="section" id="key-findings">
<h2>Key findings<a class="headerlink" href="#key-findings" title="Permalink to this headline">¶</a></h2>
<div class="section" id="predicting-thrombolysis-use-with-an-xg-boost-model">
<h3>Predicting thrombolysis use with an XG-Boost model<a class="headerlink" href="#predicting-thrombolysis-use-with-an-xg-boost-model" title="Permalink to this headline">¶</a></h3>
<p>The five most influential features predicting whether thrombolysis would be given or not were (in order of importance):</p>
<ol class="simple">
<li><p><em>Stroke type (infarction vs. haemorrhage)</em>: Use of thrombolysis depended on it being an infarction (clot).</p></li>
<li><p><em>Time from arrival at hospital to time brain imaging was performed</em>: Predicted probability of using thrombolysis reduced with increasing time to scan.</p></li>
<li><p><em>Stroke severity (NIHSS) on arrival</em>: Predicted probability of using thrombolysis was low at low NIHSS, rose with increasing NIHSS with a plateau at about NIHSS of 10-20, and then reduced with higher NIHSS.</p></li>
<li><p><em>Stroke onset time type (precise vs. estimated)</em>: Predicted probability of using thrombolysis is increased with a precisely known  onset.</p></li>
<li><p><em>Disability level (Rankin) before stroke</em>: Predicted probability of using thrombolysis reduced with increasing disability before stroke.</p></li>
</ol>
<p>Shap plots may be used to explain predictions of any individual patient (e.g. <a class="reference internal" href="#waterfall-example"><span class="std std-numref">Figure 2</span></a>).</p>
<div class="figure align-default" id="waterfall-example">
<a class="reference internal image-reference" href="../_images/xgb_waterfall_low_probability.jpg"><img alt="../_images/xgb_waterfall_low_probability.jpg" src="../_images/xgb_waterfall_low_probability.jpg" style="width: 800px;" /></a>
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">An example of a Shap <em>waterfall</em> plot showing the most influential features in influencing the model’s prediction of a patient probability of receiving thrombolysis (in this case a patient with a very low probability of receiving thrombolysis). In this example the three most influential features, reducing the chance of receiving thrombolysis were 1) slow arrival-to-scan time (138 mins), low stroke severity (NIHSS 2), and 3 the hospital attended.</span><a class="headerlink" href="#waterfall-example" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="predicting-differences-in-thrombolysis-use-between-hospitals-with-an-xg-boost-model">
<h3>Predicting <em>differences</em> in thrombolysis use between hospitals with an XG-Boost model<a class="headerlink" href="#predicting-differences-in-thrombolysis-use-between-hospitals-with-an-xg-boost-model" title="Permalink to this headline">¶</a></h3>
<p>When an XG-Boost model was trained to predict different choices in thrombolysis between units with a high or low propensity to use thrombolysis, the five most influential features were:</p>
<ol class="simple">
<li><p><em>Disability level (Rankin) before stroke</em>: lower thrombolysing units had a lower predicted probability of using thrombolysis with increasing disability before stroke.</p></li>
<li><p><em>Stroke severity (NIHSS) on arrival</em>: lower thrombolysing units had a lower predicted probability of using thrombolysis with lower stroke severity.</p></li>
<li><p><em>Stroke onset time type (precise vs. estimated)</em>: lower thrombolysing units had a lower predicted probability of using thrombolysis when the stroke onset time had been estimated.</p></li>
<li><p><em>Time from onset to arrival at hospital</em>: lower thrombolysing units had a lower predicted probability of using thrombolysis with longer onset-to-arrival times.</p></li>
<li><p><em>Time from arrival at hospital to time brain imaging was performed</em>: lower thrombolysing units had a lower predicted probability of using thrombolysis with longer arrival-to-scan times.</p></li>
</ol>
</div>
</div>
<div class="section" id="conclusions">
<h2>Conclusions<a class="headerlink" href="#conclusions" title="Permalink to this headline">¶</a></h2>
<p><em>Explainable machine learning</em> techniques give significant insight into models prediction clinical decision-making. At a global level, Shap allows for an understanding of the relationship between feature values and the model prediction, and at an individual level Shap allows for an understanding of the most influential features in any single prediction.</p>
</div>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='right-next' id="next-link" href="../xgb_with_feature_selection/outline.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Outline</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Kerry Pearn & Michael Allen<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>