{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute data from SSNAP by replacing missing (NaN) values and encoding categorical variables \n",
    "\n",
    "Also remove any patients that are not scanned, and remove columns that are highly correlated with another (refer to \"1a_understand_dataset.ipynb\" for the work that informed this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the raw data and additional files. Will need to be changed by user.\n",
    "\n",
    "data_loc = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_loc + '2019-11-04-HQIP303-Exeter_MA.csv',\n",
    "                   low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients_total = data.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StrokeTeam</th>\n",
       "      <th>PatientUID</th>\n",
       "      <th>Pathway</th>\n",
       "      <th>S1AgeOnArrival</th>\n",
       "      <th>MoreEqual80y</th>\n",
       "      <th>S1Gender</th>\n",
       "      <th>S1Ethnicity</th>\n",
       "      <th>S1OnsetInHospital</th>\n",
       "      <th>S1OnsetToArrival_min</th>\n",
       "      <th>S1OnsetDateType</th>\n",
       "      <th>...</th>\n",
       "      <th>Comorbidity</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Refusal</th>\n",
       "      <th>Age</th>\n",
       "      <th>Improving</th>\n",
       "      <th>TooMildSevere</th>\n",
       "      <th>TimeUnknownWakeUp</th>\n",
       "      <th>OtherMedical</th>\n",
       "      <th>S2ThrombolysisTime_min</th>\n",
       "      <th>S2TIAInLastMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GWOXR9160G</td>\n",
       "      <td>PSFLJ5008B</td>\n",
       "      <td>1</td>\n",
       "      <td>[85,90)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Stroke during sleep</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WTBXP2683L</td>\n",
       "      <td>HJCXV6545Z</td>\n",
       "      <td>1</td>\n",
       "      <td>[85,90)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Precise</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTBXP2683L</td>\n",
       "      <td>DGCGW7328T</td>\n",
       "      <td>1</td>\n",
       "      <td>[85,90)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Precise</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRCGI3873D</td>\n",
       "      <td>YSWGZ4558X</td>\n",
       "      <td>1</td>\n",
       "      <td>[65,70)</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best estimate</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZRRCV7012C</td>\n",
       "      <td>VBUYH5070E</td>\n",
       "      <td>1</td>\n",
       "      <td>[75,80)</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stroke during sleep</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   StrokeTeam  PatientUID  Pathway S1AgeOnArrival MoreEqual80y S1Gender  \\\n",
       "0  GWOXR9160G  PSFLJ5008B        1        [85,90)          Yes   Female   \n",
       "1  WTBXP2683L  HJCXV6545Z        1        [85,90)          Yes     Male   \n",
       "2  WTBXP2683L  DGCGW7328T        1        [85,90)          Yes   Female   \n",
       "3  GRCGI3873D  YSWGZ4558X        1        [65,70)           No   Female   \n",
       "4  ZRRCV7012C  VBUYH5070E        1        [75,80)           No     Male   \n",
       "\n",
       "  S1Ethnicity S1OnsetInHospital  S1OnsetToArrival_min      S1OnsetDateType  \\\n",
       "0       White                No                 235.0  Stroke during sleep   \n",
       "1       White                No                  70.0              Precise   \n",
       "2       White               Yes                   NaN              Precise   \n",
       "3       White                No                   NaN        Best estimate   \n",
       "4       White                No                   NaN  Stroke during sleep   \n",
       "\n",
       "   ... Comorbidity Medication Refusal Age Improving  TooMildSevere  \\\n",
       "0  ...          No         No      No  No        No             No   \n",
       "1  ...         Yes         No      No  No       Yes             No   \n",
       "2  ...         Yes        Yes      No  No        No             No   \n",
       "3  ...          No         No      No  No        No             No   \n",
       "4  ...          No         No      No  No        No             No   \n",
       "\n",
       "  TimeUnknownWakeUp OtherMedical S2ThrombolysisTime_min S2TIAInLastMonth  \n",
       "0               Yes           No                    NaN              NaN  \n",
       "1                No           No                    NaN              NaN  \n",
       "2                No           No                    NaN              NaN  \n",
       "3               Yes           No                    NaN              NaN  \n",
       "4               Yes           No                    NaN              NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import variable2type.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary maps variables used in the prediction to their data type. Variables that do not appear in the dictionary are not used for the prediction and, apart from 'S2 Thrombolysis', will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_loc + 'variable2type.json', 'r') as fp:\n",
    "    variable2type = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in data.columns:\n",
    "    \n",
    "    if feature == 'S2Thrombolysis':\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    if feature not in variable2type:\n",
    "\n",
    "        data = data.drop(feature, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StrokeTeam', 'Pathway', 'S1AgeOnArrival', 'MoreEqual80y', 'S1Gender',\n",
       "       'S1Ethnicity', 'S1OnsetInHospital', 'S1OnsetToArrival_min',\n",
       "       'S1OnsetDateType', 'S1OnsetTimeType', 'S1ArriveByAmbulance',\n",
       "       'S1AdmissionHour', 'S1AdmissionDay', 'S1AdmissionQuarter',\n",
       "       'S1AdmissionYear', 'CongestiveHeartFailure', 'Hypertension',\n",
       "       'AtrialFibrillation', 'Diabetes', 'StrokeTIA', 'AFAntiplatelet',\n",
       "       'AFAnticoagulent', 'AFAnticoagulentVitK', 'AFAnticoagulentDOAC',\n",
       "       'AFAnticoagulentHeparin', 'S2NewAFDiagnosis', 'S2RankinBeforeStroke',\n",
       "       'Loc', 'LocQuestions', 'LocCommands', 'BestGaze', 'Visual',\n",
       "       'FacialPalsy', 'MotorArmLeft', 'MotorArmRight', 'MotorLegLeft',\n",
       "       'MotorLegRight', 'LimbAtaxia', 'Sensory', 'BestLanguage', 'Dysarthria',\n",
       "       'ExtinctionInattention', 'S2NihssArrival', 'S2BrainImagingTime_min',\n",
       "       'S2StrokeType', 'S2Thrombolysis', 'S2TIAInLastMonth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import variable2method.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_loc + 'variable2method.json', 'r') as fp:\n",
    "    variable2method = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1OnsetToArrival_min': '9999',\n",
       " 'S1ArriveByAmbulance': 'missing',\n",
       " 'AFAntiplatelet': 'missing',\n",
       " 'AFAnticoagulent': 'missing',\n",
       " 'AFAnticoagulentVitK': 'missing',\n",
       " 'AFAnticoagulentDOAC': 'missing',\n",
       " 'AFAnticoagulentHeparin': 'missing',\n",
       " 'S2NewAFDiagnosis': 'missing',\n",
       " 'LocQuestions': 'zero',\n",
       " 'LocCommands': 'zero',\n",
       " 'BestGaze': 'zero',\n",
       " 'Visual': 'zero',\n",
       " 'FacialPalsy': 'zero',\n",
       " 'MotorArmLeft': 'zero',\n",
       " 'MotorArmRight': 'zero',\n",
       " 'MotorLegLeft': 'zero',\n",
       " 'MotorLegRight': 'zero',\n",
       " 'LimbAtaxia': 'zero',\n",
       " 'Sensory': 'zero',\n",
       " 'BestLanguage': 'zero',\n",
       " 'Dysarthria': 'zero',\n",
       " 'ExtinctionInattention': 'zero',\n",
       " 'S2NihssArrival': 'zero',\n",
       " 'S2BrainImagingTime_min': '9999',\n",
       " 'S2StrokeType': 'missing',\n",
       " 'S2TIAInLastMonth': 'missing'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable2method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable2method['S2NihssArrival'] = 'sum'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values in this dictionary correspond to the following methods:\n",
    "\n",
    "- 9999: replace missing values with 9999\n",
    "- zero: replace missing values with zero\n",
    "- missing: replace missing values with a text label 'missing' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Replace all NaN values according to the process in variable2method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loc', 'LocQuestions', 'LocCommands', 'BestGaze', 'Visual',\n",
       "       'FacialPalsy', 'MotorArmLeft', 'MotorArmRight', 'MotorLegLeft',\n",
       "       'MotorLegRight', 'LimbAtaxia', 'Sensory', 'BestLanguage', 'Dysarthria',\n",
       "       'ExtinctionInattention', 'S2NihssArrival'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[27:43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = data.copy()\n",
    "\n",
    "for variable, method in variable2method.items():\n",
    "    \n",
    "    series = imputed[variable].copy()\n",
    "    missing = series.isna()\n",
    "    \n",
    "    if method=='missing':\n",
    "        \n",
    "        series[missing] = 'missing'\n",
    "        \n",
    "    elif method=='zero':\n",
    "        \n",
    "        series[missing] = 0\n",
    "        \n",
    "    elif method=='9999':\n",
    "        \n",
    "        series[missing] = 9999\n",
    "        \n",
    "    elif method=='sum':\n",
    "        \n",
    "        series[missing] = imputed[data.columns[27:43]].sum(axis=1)\n",
    "        \n",
    "    else:\n",
    "        raise Exception('{0} not a valid method'.format(method))\n",
    "        \n",
    "    imputed[variable] = series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Use one-hot-encoding to encode all categorical and binary (text) variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If preparing data for neural network or train test by hospital, uncomment lines 9 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = imputed.copy()\n",
    "\n",
    "variable2family={}\n",
    "\n",
    "for variable, type_ in variable2type.items():\n",
    "    \n",
    "    if type_ in ['Categorical', 'Binary']:\n",
    "        \n",
    "        if variable == 'StrokeTeam':\n",
    "            continue\n",
    "\n",
    "        to_code = encoded[variable]\n",
    "        \n",
    "        if type_ == 'Binary': \n",
    "            \n",
    "            coded = pd.get_dummies(to_code, prefix=variable)\n",
    "            \n",
    "        else:\n",
    "            coded = pd.get_dummies(to_code, prefix=variable)\n",
    "        \n",
    "        encoded = pd.concat([encoded, coded], axis=1)\n",
    "        encoded.drop([variable], axis=1, inplace=True)\n",
    "        \n",
    "        variable2family[variable] = coded.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_loc + 'variable2family.json', 'w') as f: \n",
    "    json.dump(variable2family, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Encode 'S2Thrombolysis' to target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[]\n",
    "for outcome in encoded.S2Thrombolysis.values:\n",
    "    \n",
    "    if outcome in ['No', 'No but']:\n",
    "        \n",
    "        target.append(0)\n",
    "        \n",
    "    elif outcome == 'Yes': \n",
    "        \n",
    "        target.append(1)\n",
    "        \n",
    "encoded['S2Thrombolysis'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Change 'S1AgeOnArrival' to midpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for group in encoded.S1AgeOnArrival.values:\n",
    "    minage, maxage = group.split(',')\n",
    "    \n",
    "    minage = int(''.join(list(minage)[1:]))\n",
    "    maxage = int(''.join(list(maxage)[:-1]))\n",
    "    \n",
    "    ages.append(np.median([minage,maxage]))\n",
    "    \n",
    "encoded['S1AgeOnArrival'] = ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict data \n",
    "\n",
    "Restriction 1. Patients that attend a hospital with at least 300 admissions and 10 thrombolysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list for dataframe groups\n",
    "keep = []\n",
    "\n",
    "groups = encoded.groupby('StrokeTeam') # creates a new object of groups of data\n",
    "\n",
    "for index, group_df in groups: # each group has an index and a dataframe of data\n",
    "    \n",
    "    # Skip if total admiision less than 300 or total thrombolysis < 10\n",
    "    if (group_df.shape[0] < 300) or (group_df['S2Thrombolysis'].sum() < 10):\n",
    "        continue\n",
    "    \n",
    "    else: \n",
    "        keep.append(group_df)\n",
    "\n",
    "# Concatenate output\n",
    "filtered_data = pd.DataFrame()\n",
    "filtered_data = pd.concat(keep)\n",
    "\n",
    "n_patients_after_admission_restrictions = filtered_data.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restriction 2. Patients who have their stroke onset out of hospital with onset to arrival of 4 hours or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data[(filtered_data['S1OnsetInHospital_Yes']==0) & \n",
    "                              (filtered_data['S1OnsetToArrival_min']<= 240)]\n",
    "\n",
    "n_patients_after_arrival_restrictions = filtered_data.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restriction 3. Patients that have a scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = filtered_data['S2BrainImagingTime_min']!=9999\n",
    "filtered_data = filtered_data[mask]\n",
    "\n",
    "n_patients_after_need_a_scan_restrictions = filtered_data.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of number of patients after filter data at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 246676 patients in total\n",
      "There are 239505 patients after hospital admission restrictions\n",
      "There are 88928 patients after arrival time <4hours and onset out of hospital restriction\n",
      "There are 88792 patients after need to have a scan restrictions\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {n_patients_total} patients in total\")\n",
    "print(f\"There are {n_patients_after_admission_restrictions} patients after \"\n",
    "      f\"hospital admission restrictions\")\n",
    "print(f\"There are {n_patients_after_arrival_restrictions} patients after \"\n",
    "      f\"arrival time <4hours and onset out of hospital restriction\")\n",
    "print(f\"There are {n_patients_after_need_a_scan_restrictions} patients after \"\n",
    "      f\"need to have a scan restrictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns\n",
    "### Motivation to learn which columns to drop\n",
    "\n",
    "In SAMueL2 we will focus more on the explanability of the models. We will do this by looking at the importance of the feature in the model, and also the features SHAP value (the contribution of a feature to the target value). Therefore it is now more useful for us to remove any feature with a near perfect correlation with another feature. Say we have two binary variables, one recording if the patient is female and another recording is a patient is male. These both provide the model with the same information and so one model may give \"female\" a score of 10, amd \"male\" a score of 0, and another may give both a score of 5. When look at the features in terms of ranked importance, having the data represented in this way complicates the interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['MoreEqual80y_No','S1Gender_Male','S1OnsetInHospital_No',\n",
    "                   'CongestiveHeartFailure_No','Hypertension_No',\n",
    "                   'AtrialFibrillation_No', 'Diabetes_No', 'StrokeTIA_No',\n",
    "                   'AFAntiplatelet_missing',\n",
    "                   'S1ArriveByAmbulance_missing',\n",
    "                   'S2StrokeType_missing',\n",
    "                   'S2StrokeType_Primary Intracerebral Haemorrhage',\n",
    "                   'S1OnsetTimeType_Best estimate', 'S1OnsetTimeType_Not known']\n",
    "\n",
    "filtered_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save imputed data to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv(\n",
    "    data_loc + '220401_national_data_imputed_filtered_no_unit_encoding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode units and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = filtered_data['StrokeTeam']\n",
    "filtered_data.drop(['StrokeTeam'],inplace=True, axis=1)\n",
    "one_hot_coded = pd.get_dummies(units, prefix='StrokeTeam')\n",
    "filtered_data = pd.concat([filtered_data, one_hot_coded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv(\n",
    "    data_loc + '220401_national_data_imputed_filtered_with_unit_encoding.csv', \n",
    "    index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
