{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "340334e5",
   "metadata": {},
   "source": [
    "# XGBoost feature selection\n",
    "(using stratified 5-fold cross validation)\n",
    "\n",
    "## Plain English summary\n",
    "Machine learning algorithms (such as XGBoost) were devised to deal with enormous and complex datasets, with the approach that the more data that you can throw at them, the better, and let the algorithms work it out themselves. \n",
    "\n",
    "However this approach can make it tricky to be able to explain a coherent story about how the models are working, the relationships that they have found, and how they have made their predictions. \n",
    "\n",
    "Our machine learning work has taken on an additional focus - to make our work as explainable as possible. Both in terms of being able to explain how the models have arrived at their outcome, and in the ease at which we can disseminate our work to a wider audience. For us to have explainable models we want to have a balance between model complexity and model accuracy in order to be able to explain our models, whilst maintaining model performance. \n",
    "\n",
    "In this notebook we create a model to predict if a patient should receive thrombolysis using just a single input feature, chosen as the feature that gave the model it's best performance. The single feature that gave the best model performance was \"Arrival-to-scan time\". Fixing this feature in the model, we repeated the process to chose the next single feature to add to the model. The best single feature to include next was \"Stroke type\". We repeated this process, choosing the next feature to add to the model until 25 features were included (it was limited to 25 features for computational time purposes). We found that a model with eight features is able to provide 99% of the accuracy obtained when all 84 features are used, and that these eight features are also independent of each other (refer to section *Check correlation between selected features* to confirm this). \n",
    "\n",
    "This is not saying that these are the 8 most important features, as another highly correlated feature may also have been important, but it is now not needed to be included in the model.\n",
    "\n",
    "We will train future models using these eight features.\n",
    "\n",
    "## Model and data\n",
    "\n",
    "XGBoost models were trained on stratified k-fold cross-validation data. The full dataset contains 84 features that describe the patient (in terms of their clinical characteristics, the stroke pathway, and the stroke team that they attended). Features to be included in the model were sequentially selected as the single best feature to add to the model in terms of performance from the area under the receiver operating characteristic (ROC AUC) curve. When included, the hospital feature is included as a one-hot encoded feature.\n",
    "\n",
    "## Aims\n",
    "\n",
    "* Select up to 25 features (from the full set of 84 features) using forward feature selection. Features are selected sequentially (using the greedy approach), choosing the feature that leads to most improvement in ROC AUC score.\n",
    "* Decide on the number of features to include in future models\n",
    "\n",
    "## Observations\n",
    "Eight features are able to provide a ROC AUC of 0.917 out of a maximum of 0.922. These features are also independent of each other.\n",
    "\n",
    "Our best model with 1, 2, 8 & 84 features had a ROC AUC of 0.715, 0.792, 0.917 & 0.922."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca30286",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee409e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f166bdf-870b-499b-bcbe-ff00fd9b3e5c",
   "metadata": {},
   "source": [
    "## Create output folder if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37755327-1974-4049-9db8-e1dd16c43cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './output'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574dc5cc",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Data has previously been split into 5 stratified k-fold splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9211904",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "data_loc = '../data/kfold_5fold/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eaf7655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = [], []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    train_data.append(pd.read_csv(data_loc + 'train_{0}.csv'.format(i)))\n",
    "    test_data.append(pd.read_csv(data_loc + 'test_{0}.csv'.format(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a95d6-8384-4c28-a2ad-174a66014a1d",
   "metadata": {},
   "source": [
    "## Get list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4eb0d4-6aa9-4e30-af7d-4399d61f0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbcfc5f",
   "metadata": {},
   "source": [
    "## Fit XGBoost model\n",
    "\n",
    "Loop through each feature in turn and train an XGBoost model with that feature added to the dataset (for each k-fold split). Choose the single best feature to add to the model in terms of performance from the ROC AUC (mean of the k-fold splits).\n",
    "\n",
    "Repeat until 25 features have been selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1895bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to store accuracies and chosen features\n",
    "roc_auc_by_feature_number = []\n",
    "roc_auc_by_feature_number_kfold = []\n",
    "chosen_features = []\n",
    "\n",
    "# Initialise chosen features list and run tracker\n",
    "available_features = list(train_data[0].drop('S2Thrombolysis', axis=1))\n",
    "number_of_features = len(available_features)\n",
    "\n",
    "# Loop through number of features\n",
    "for i in range (25):\n",
    "    \n",
    "    # Reset best feature and accuracy\n",
    "    best_result = 0\n",
    "    best_feature = ''\n",
    "    \n",
    "    # Loop through available features\n",
    "    for feature in available_features:\n",
    "\n",
    "        # Create copy of already chosen features to avoid original being changed\n",
    "        features_to_use = chosen_features.copy()\n",
    "        # Create a list of features from features already chosen + 1 new feature\n",
    "        features_to_use.append(feature)\n",
    "        \n",
    "        # Set up a list to hold AUC results for this feature for each kfold\n",
    "        feature_auc_kfold = []\n",
    "        \n",
    "        # Loop through k folds\n",
    "        for k_fold in range(5):\n",
    "\n",
    "            # Get k fold split\n",
    "            train = train_data[k_fold]\n",
    "            test = test_data[k_fold]\n",
    "\n",
    "            # Get X and y\n",
    "            X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "            X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "            y_train = train['S2Thrombolysis']\n",
    "            y_test = test['S2Thrombolysis']\n",
    "            \n",
    "            # Restrict features\n",
    "            X_train = X_train[features_to_use]\n",
    "            X_test = X_test[features_to_use]\n",
    "    \n",
    "            # One hot encode hospitals if hospital in features used\n",
    "            if 'StrokeTeam' in features_to_use:\n",
    "                X_train_hosp = pd.get_dummies(\n",
    "                    X_train['StrokeTeam'], prefix = 'team')\n",
    "                X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "                X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "                X_test_hosp = pd.get_dummies(\n",
    "                    X_test['StrokeTeam'], prefix = 'team')\n",
    "                X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "                X_test.drop('StrokeTeam', axis=1, inplace=True)    \n",
    "\n",
    "            # Define model\n",
    "            model = XGBClassifier(verbosity = 0, seed=42, learning_rate=0.5)\n",
    "\n",
    "            # Fit model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Get predicted probabilities\n",
    "            y_probs = model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "            # Get ROC AUC\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            feature_auc_kfold.append(roc_auc)\n",
    "        \n",
    "        # Get average result from all k-fold splits\n",
    "        feature_auc_mean = np.mean(feature_auc_kfold)\n",
    "    \n",
    "        # Update chosen feature and result if this feature is a new best\n",
    "        if feature_auc_mean > best_result:\n",
    "            best_result = feature_auc_mean\n",
    "            best_result_kfold = feature_auc_kfold\n",
    "            best_feature = feature\n",
    "            \n",
    "    # k-fold splits are complete    \n",
    "    # Add mean accuracy and AUC to record of accuracy by feature number\n",
    "    roc_auc_by_feature_number.append(best_result)\n",
    "    roc_auc_by_feature_number_kfold.append(best_result_kfold)\n",
    "    chosen_features.append(best_feature)\n",
    "    available_features.remove(best_feature)\n",
    "            \n",
    "    print (f'Feature {i+1:2.0f}: {best_feature}, AUC: {best_result:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddaec99-e6dd-4c54-b5f8-72403c4e8e30",
   "metadata": {},
   "source": [
    "Create a dataframe that contains the chosen features, and their mean ROC AUC across the k-fold splits, and the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa2b56-d156-4997-997d-8dc01b208eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['number_features'] = range(1, len(chosen_features)+1)\n",
    "results['feature'] = chosen_features\n",
    "results['AUC'] = roc_auc_by_feature_number\n",
    "results['AUC_Std'] = [np.std(auc) for auc in roc_auc_by_feature_number_kfold]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b01c46-9dd9-4c8d-9099-4bc46a4503a7",
   "metadata": {},
   "source": [
    "## Plot the results\n",
    "\n",
    "Plot a line graph showing the change in mean ROC AUC (across k-fold splits) for the number of features chosen in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79147fe1-4bc5-424f-9c30-b13d908efe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_show = 10\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(results['number_features'], results['AUC'])\n",
    "ax1.set_xlabel('Number of features')\n",
    "ax1.set_ylabel('Mean ROC AUC')\n",
    "ax1.set_ylim(0.7, 0.95)\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(results['feature'][:features_to_show],\n",
    "         results['AUC'][:features_to_show])\n",
    "xlabels = list(results['feature'])\n",
    "xlabels = xlabels[:features_to_show]\n",
    "ax2.set_xticklabels(xlabels, rotation=45, ha='right')\n",
    "ax2.set_ylabel('Mean ROC AUC')\n",
    "ax1.set_xlabel('New feature selected')\n",
    "ax2.set_ylim(0.7, 0.95)\n",
    "ax2.grid()\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.savefig(f'./output/feature_selection.jpg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ababa4-e671-4ff8-9c41-d22da3ae7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./output/feature_selection.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54850619-562d-4ff3-9293-12d9551c9ebd",
   "metadata": {},
   "source": [
    "## Create dictionary for plain English feature names\n",
    "\n",
    "Use plain English terms in the DataFrame for the 8 features selected to be in the model (and for the target feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59356121-41f0-463e-93b2-3023f2bc35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name_dict = {\n",
    "    \"S2BrainImagingTime_min\": \"Arrival-to-scan time\",\n",
    "    \"S2StrokeType_Infarction\": \"Infarction\",\n",
    "    \"S2NihssArrival\": \"Stroke severity\",\n",
    "    \"S1OnsetTimeType_Precise\": \"Precise onset time\",\n",
    "    \"S2RankinBeforeStroke\": \"Prior disability level\",\n",
    "    \"StrokeTeam\": \"Stroke team\",\n",
    "    \"AFAnticoagulent_Yes\": \"Use of AF anticoagulants\",\n",
    "    \"S1OnsetToArrival_min\": \"Onset-to-arrival time\",\n",
    "    \"S2Thrombolysis\": \"Thrombolysis\",\n",
    "    \"S1OnsetDateType_Stroke during sleep\":\"Onset during sleep\",\n",
    "    \"S1AgeOnArrival\":\"Age\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409f9b9-9437-4e3d-be0c-0f2d5151d665",
   "metadata": {},
   "source": [
    "Save dictionary as a json (to be read in and used by the other notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bec702-483b-49f7-b647-9eb90c3ceb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./output/feature_name_dict.json\", \"w+\") as f:\n",
    "    json.dump(feature_name_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc1d94-4801-4768-b4a9-02f4df579b58",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Observations\n",
    "\n",
    "Ten features are able to provide a ROC AUC of 0.915 out of a maximum of 0.922. These features are also independent of each other (see the next section *Check correlation between selected features* that confirms this). \n",
    "\n",
    "These 8 features are:\n",
    "\n",
    "* S2BrainImagingTime_min: Time from arrival at hospital to scan (mins)\n",
    "* S2StrokeType_Infarction: Stroke type (1 = infarction, 0 = haemorrhage)\n",
    "* S2NihssArrival: Stroke severity (NIHSS) on arrival\n",
    "* S1OnsetTimeType_Precise: Onset time type (1 = precise, 0 = best estimate)\n",
    "* S2RankinBeforeStroke: Disability level (Modified Rankin Scale) before stroke\n",
    "* StrokeTeam: Hospital attended\n",
    "* AFAnticoagulent_Yes: Use of atrial fibrillation anticoagulant (1 = Yes, 0 = No)\n",
    "* S1OnsetToArrival_min: Time from onset of stroke to arrival at hospital (mins)\n",
    "\n",
    "Columns will be renamed to use these plain English terms in the dataframe in the onwards notebooks:\n",
    "\n",
    "* \"S2BrainImagingTime_min\": \"Arrival-to-scan time\"\n",
    "* \"S2StrokeType_Infarction\": \"Infarction\"\n",
    "* \"S2NihssArrival\": \"Stroke severity\"\n",
    "* \"S1OnsetTimeType_Precise\": \"Precise onset time\"\n",
    "* \"S2RankinBeforeStroke\": \"Prior disability level\"\n",
    "* \"StrokeTeam\": \"Stroke team\"\n",
    "* \"AFAnticoagulent_Yes\": \"Use of AF anticoagulents\"\n",
    "* \"S1OnsetToArrival_min\": \"Onset-to-arrival time\"\n",
    "* \"S2Thrombolysis\": \"Thrombolysis\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b368e36a85415766688ec72e3e874a4b525584eabf4bf7122952a4e0fd64fcde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
