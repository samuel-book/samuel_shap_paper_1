{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of artificial (synthetic) patient data\n",
    "\n",
    "Note: This artificial data is intended only for use in exploring the methods, using up to 10 features. The method of synthethis does not maintain any covariance between features (as feature values are created independetly of each other, to eliminate any risk of identifying original data), though average feature values for patients at each hopsital are approximately maintained. These data may be used to train models with minimal loss of accuracy.\n",
    "\n",
    "The key methodology is:\n",
    "\n",
    "* Remove thrombolysis label\n",
    "* Group original data by hopsital\n",
    "    * For each of 10 features take bootstrap samples of that feature\n",
    "* Combine data across hospitals\n",
    "* Train an XGBoost model on original data to predict use of thrombolysis\n",
    "* Use the XGBoost model to leabl the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loc = '../data/10k_training_test/'\n",
    "original_data = pd.read_csv(data_loc + 'cohort_10000_train.csv')\n",
    "\n",
    "# Get stroke teams = \n",
    "stroke_teams = list(set(original_data['StrokeTeam']))\n",
    "stroke_teams.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unlabelled synthetic data by bootstrap sampling from individual feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = 1000\n",
    "synthetic_data_list = []\n",
    "\n",
    "# Sample data for each stroke team\n",
    "for stroke_team in stroke_teams:\n",
    "    # Set up data frame for synthetic team data\n",
    "    synthetic_data = pd.DataFrame()\n",
    "    \n",
    "    # Get original team data\n",
    "    mask = original_data['StrokeTeam'] == stroke_team\n",
    "    team_data = original_data[mask]\n",
    "    \n",
    "    # Set team\n",
    "    synthetic_data['StrokeTeam'] = np.repeat(stroke_team, cases)\n",
    "\n",
    "    # Sample individual items from orioginal data with replacement\n",
    "    \n",
    "    synthetic_data['S2BrainImagingTime_min'] = np.random.choice(\n",
    "        team_data['S2BrainImagingTime_min'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data['S2StrokeType_Infarction'] = np.random.choice(\n",
    "        team_data['S2StrokeType_Infarction'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data['S2NihssArrival'] = np.random.choice(\n",
    "        team_data['S2NihssArrival'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['S1OnsetTimeType_Precise'] = np.random.choice(\n",
    "        team_data['S1OnsetTimeType_Precise'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['S2RankinBeforeStroke'] = np.random.choice(\n",
    "        team_data['S2RankinBeforeStroke'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['AFAnticoagulent_Yes'] = np.random.choice(\n",
    "        team_data['AFAnticoagulent_Yes'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data['S1OnsetToArrival_min'] = np.random.choice(\n",
    "        team_data['S1OnsetToArrival_min'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['S1OnsetDateType_Stroke during sleep'] = np.random.choice(\n",
    "        team_data['S1OnsetDateType_Stroke during sleep'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['S1AgeOnArrival'] = np.random.choice(\n",
    "        team_data['S1AgeOnArrival'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data_list.append(synthetic_data)\n",
    "\n",
    "# Concatenate lists\n",
    "synthetic_data_df = pd.concat(synthetic_data_list)\n",
    "\n",
    "# Shuffle data\n",
    "synthetic_data_df = synthetic_data_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model on original data, to use to label synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(data_loc + 'cohort_10000_train.csv')\n",
    "test = pd.read_csv(data_loc + 'cohort_10000_test.csv')\n",
    "\n",
    "# Read in the names of the selected features for the model\n",
    "number_of_features_to_use = 10\n",
    "key_features = pd.read_csv('./output/feature_selection.csv')\n",
    "key_features = list(key_features['feature'])[:number_of_features_to_use]\n",
    "# And add the target feature name: S2Thrombolysis\n",
    "key_features.append('S2Thrombolysis')\n",
    "\n",
    "# Select features\n",
    "train = train[key_features]\n",
    "test = test[key_features]\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['StrokeTeam'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['StrokeTeam'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "X_test.drop('StrokeTeam', axis=1, inplace=True)    \n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_test)[:,1]\n",
    "y_pred = y_probs > 0.5\n",
    "\n",
    "# Show accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print (f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict label for synthetic data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode hopsitals\n",
    "X_synthetic = synthetic_data_df\n",
    "X_synthetic_hosp = pd.get_dummies(X_synthetic['StrokeTeam'], prefix = 'team')\n",
    "X_synthetic = pd.concat([X_synthetic, X_synthetic_hosp], axis=1)\n",
    "X_synthetic.drop('StrokeTeam', axis=1, inplace=True)\n",
    "\n",
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_synthetic)[:,1]\n",
    "y_pred = y_probs > 0.5\n",
    "synthetic_data_df['S2Thrombolysis'] = y_pred * 1.0\n",
    "\n",
    "# Save\n",
    "synthetic_data_df.to_csv('./output/synthetic_10K_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test synthetic data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = synthetic_data_df\n",
    "test = pd.read_csv(data_loc + 'cohort_10000_test.csv')\n",
    "\n",
    "# Read in the names of the selected features for the model\n",
    "number_of_features_to_use = 10\n",
    "key_features = pd.read_csv('./output/feature_selection.csv')\n",
    "key_features = list(key_features['feature'])[:number_of_features_to_use]\n",
    "# And add the target feature name: S2Thrombolysis\n",
    "key_features.append('S2Thrombolysis')\n",
    "\n",
    "# Select features\n",
    "train = train[key_features]\n",
    "test = test[key_features]\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['StrokeTeam'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['StrokeTeam'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "X_test.drop('StrokeTeam', axis=1, inplace=True)    \n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_test)[:,1]\n",
    "y_pred = y_probs > 0.5\n",
    "\n",
    "# Show accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print (f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before duplicate removal: 132000\n",
      "Size after duplicate removal: 131988\n"
     ]
    }
   ],
   "source": [
    "print (f'Size before duplicate removal: {synthetic_data_df.shape[0]}')\n",
    "synthetic_data_df = synthetic_data_df.drop_duplicates()\n",
    "print (f'Size after duplicate removal: {synthetic_data_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create k-fold data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify by thrombolysis and stroke team\n",
    "strat = synthetic_data_df['StrokeTeam'].map(str) + '-' + synthetic_data_df['S2Thrombolysis'].map(str)\n",
    "\n",
    "# Set up splits\n",
    "number_of_splits = 5\n",
    "skf = StratifiedKFold(n_splits = number_of_splits)\n",
    "skf.get_n_splits(synthetic_data_df, strat.values)\n",
    "\n",
    "# Put in NumPy arrays\n",
    "X = synthetic_data_df.values\n",
    "y = strat.values\n",
    "X_col_names = list(synthetic_data_df)\n",
    "\n",
    "# Loop through the k-fold splits\n",
    "counter = 0\n",
    "for train_index, test_index in skf.split(X, y):  \n",
    "    \n",
    "    # Get Xtrain and test\n",
    "    train_np, test_np = X[train_index], X[test_index]\n",
    "    \n",
    "    # Convert to Pandas DataFrames\n",
    "    train = pd.DataFrame(train_np, columns=X_col_names)\n",
    "    test = pd.DataFrame(test_np, columns=X_col_names)\n",
    "    \n",
    "    # Save\n",
    "    train.to_csv(f'./output/kfold_5fold/train_{counter}.csv', index=False)\n",
    "    test.to_csv(f'./output/kfold_5fold/test_{counter}.csv', index=False)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new 10k training and test data sets\n",
    "\n",
    "Create new 10k training and test data sets, based on synthetic data derived from the original 10k training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = synthetic_data_df.drop('S2Thrombolysis', axis=1)\n",
    "y = synthetic_data_df['S2Thrombolysis']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=10000, stratify=strat, random_state=42)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "\n",
    "train.to_csv('./output/10k_training_test/cohort_10000_train.csv', index=False)\n",
    "test.to_csv('./output/10k_training_test/cohort_10000_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm loss of covariance between features\n",
    "\n",
    "Confirm loss of covariance between features to confirm that features values a rebeing selected independently from each other (and so cannot represent an identifyable patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>r-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <td>S1OnsetDateType_Stroke during sleep</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetDateType_Stroke during sleep</th>\n",
       "      <td>S2RankinBeforeStroke</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <td>S2NihssArrival</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2RankinBeforeStroke</th>\n",
       "      <td>S1AgeOnArrival</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2RankinBeforeStroke</th>\n",
       "      <td>S1OnsetToArrival_min</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFAnticoagulent_Yes</th>\n",
       "      <td>S1AgeOnArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2StrokeType_Infarction</th>\n",
       "      <td>S1OnsetTimeType_Precise</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <td>S1OnsetToArrival_min</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <td>S2BrainImagingTime_min</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <td>S2NihssArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <td>S2RankinBeforeStroke</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetToArrival_min</th>\n",
       "      <td>S2NihssArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <td>S1OnsetToArrival_min</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2StrokeType_Infarction</th>\n",
       "      <td>S1OnsetToArrival_min</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <td>S2RankinBeforeStroke</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <td>S2StrokeType_Infarction</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2NihssArrival</th>\n",
       "      <td>S2RankinBeforeStroke</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2NihssArrival</th>\n",
       "      <td>S2StrokeType_Infarction</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetDateType_Stroke during sleep</th>\n",
       "      <td>S2StrokeType_Infarction</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2NihssArrival</th>\n",
       "      <td>S1OnsetDateType_Stroke during sleep</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFAnticoagulent_Yes</th>\n",
       "      <td>S1OnsetDateType_Stroke during sleep</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <td>S1OnsetDateType_Stroke during sleep</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetToArrival_min</th>\n",
       "      <td>S1OnsetDateType_Stroke during sleep</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1AgeOnArrival</th>\n",
       "      <td>S2StrokeType_Infarction</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1AgeOnArrival</th>\n",
       "      <td>S2NihssArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <td>S1AgeOnArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetToArrival_min</th>\n",
       "      <td>S1AgeOnArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <td>S1AgeOnArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetDateType_Stroke during sleep</th>\n",
       "      <td>S1AgeOnArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2StrokeType_Infarction</th>\n",
       "      <td>AFAnticoagulent_Yes</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFAnticoagulent_Yes</th>\n",
       "      <td>S2RankinBeforeStroke</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFAnticoagulent_Yes</th>\n",
       "      <td>S2NihssArrival</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <td>AFAnticoagulent_Yes</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFAnticoagulent_Yes</th>\n",
       "      <td>S1OnsetToArrival_min</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <td>AFAnticoagulent_Yes</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2RankinBeforeStroke</th>\n",
       "      <td>S2StrokeType_Infarction</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                variable  \\\n",
       "S1OnsetTimeType_Precise              S1OnsetDateType_Stroke during sleep   \n",
       "S1OnsetDateType_Stroke during sleep                 S2RankinBeforeStroke   \n",
       "S2BrainImagingTime_min                                    S2NihssArrival   \n",
       "S2RankinBeforeStroke                                      S1AgeOnArrival   \n",
       "S2RankinBeforeStroke                                S1OnsetToArrival_min   \n",
       "AFAnticoagulent_Yes                                       S1AgeOnArrival   \n",
       "S2StrokeType_Infarction                          S1OnsetTimeType_Precise   \n",
       "S1OnsetTimeType_Precise                             S1OnsetToArrival_min   \n",
       "S1OnsetTimeType_Precise                           S2BrainImagingTime_min   \n",
       "S1OnsetTimeType_Precise                                   S2NihssArrival   \n",
       "S1OnsetTimeType_Precise                             S2RankinBeforeStroke   \n",
       "S1OnsetToArrival_min                                      S2NihssArrival   \n",
       "S2BrainImagingTime_min                              S1OnsetToArrival_min   \n",
       "S2StrokeType_Infarction                             S1OnsetToArrival_min   \n",
       "S2BrainImagingTime_min                              S2RankinBeforeStroke   \n",
       "S2BrainImagingTime_min                           S2StrokeType_Infarction   \n",
       "S2NihssArrival                                      S2RankinBeforeStroke   \n",
       "S2NihssArrival                                   S2StrokeType_Infarction   \n",
       "S1OnsetDateType_Stroke during sleep              S2StrokeType_Infarction   \n",
       "S2NihssArrival                       S1OnsetDateType_Stroke during sleep   \n",
       "AFAnticoagulent_Yes                  S1OnsetDateType_Stroke during sleep   \n",
       "S2BrainImagingTime_min               S1OnsetDateType_Stroke during sleep   \n",
       "S1OnsetToArrival_min                 S1OnsetDateType_Stroke during sleep   \n",
       "S1AgeOnArrival                                   S2StrokeType_Infarction   \n",
       "S1AgeOnArrival                                            S2NihssArrival   \n",
       "S2BrainImagingTime_min                                    S1AgeOnArrival   \n",
       "S1OnsetToArrival_min                                      S1AgeOnArrival   \n",
       "S1OnsetTimeType_Precise                                   S1AgeOnArrival   \n",
       "S1OnsetDateType_Stroke during sleep                       S1AgeOnArrival   \n",
       "S2StrokeType_Infarction                              AFAnticoagulent_Yes   \n",
       "AFAnticoagulent_Yes                                 S2RankinBeforeStroke   \n",
       "AFAnticoagulent_Yes                                       S2NihssArrival   \n",
       "S2BrainImagingTime_min                               AFAnticoagulent_Yes   \n",
       "AFAnticoagulent_Yes                                 S1OnsetToArrival_min   \n",
       "S1OnsetTimeType_Precise                              AFAnticoagulent_Yes   \n",
       "S2RankinBeforeStroke                             S2StrokeType_Infarction   \n",
       "\n",
       "                                     r-squared  \n",
       "S1OnsetTimeType_Precise                 0.0002  \n",
       "S1OnsetDateType_Stroke during sleep     0.0002  \n",
       "S2BrainImagingTime_min                  0.0001  \n",
       "S2RankinBeforeStroke                    0.0001  \n",
       "S2RankinBeforeStroke                    0.0001  \n",
       "AFAnticoagulent_Yes                     0.0000  \n",
       "S2StrokeType_Infarction                 0.0000  \n",
       "S1OnsetTimeType_Precise                 0.0000  \n",
       "S1OnsetTimeType_Precise                 0.0000  \n",
       "S1OnsetTimeType_Precise                 0.0000  \n",
       "S1OnsetTimeType_Precise                 0.0000  \n",
       "S1OnsetToArrival_min                    0.0000  \n",
       "S2BrainImagingTime_min                  0.0000  \n",
       "S2StrokeType_Infarction                 0.0000  \n",
       "S2BrainImagingTime_min                  0.0000  \n",
       "S2BrainImagingTime_min                  0.0000  \n",
       "S2NihssArrival                          0.0000  \n",
       "S2NihssArrival                          0.0000  \n",
       "S1OnsetDateType_Stroke during sleep     0.0000  \n",
       "S2NihssArrival                          0.0000  \n",
       "AFAnticoagulent_Yes                     0.0000  \n",
       "S2BrainImagingTime_min                  0.0000  \n",
       "S1OnsetToArrival_min                    0.0000  \n",
       "S1AgeOnArrival                          0.0000  \n",
       "S1AgeOnArrival                          0.0000  \n",
       "S2BrainImagingTime_min                  0.0000  \n",
       "S1OnsetToArrival_min                    0.0000  \n",
       "S1OnsetTimeType_Precise                 0.0000  \n",
       "S1OnsetDateType_Stroke during sleep     0.0000  \n",
       "S2StrokeType_Infarction                 0.0000  \n",
       "AFAnticoagulent_Yes                     0.0000  \n",
       "AFAnticoagulent_Yes                     0.0000  \n",
       "S2BrainImagingTime_min                  0.0000  \n",
       "AFAnticoagulent_Yes                     0.0000  \n",
       "S1OnsetTimeType_Precise                 0.0000  \n",
       "S2RankinBeforeStroke                    0.0000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop stroke team and thrombolysis\n",
    "synthetic_data_df.drop('StrokeTeam', axis=1, inplace=True)\n",
    "synthetic_data_df.drop('S2Thrombolysis', axis=1, inplace=True)\n",
    "\n",
    "# Scale data\n",
    "sc = StandardScaler() \n",
    "sc.fit(synthetic_data_df)\n",
    "data_std = sc.transform(synthetic_data_df)\n",
    "data_std = pd.DataFrame(data_std, columns=list(synthetic_data_df))\n",
    "\n",
    "# Get covariance\n",
    "cov = data_std.cov()\n",
    "\n",
    "# Convert from wide to tall\n",
    "cov = cov.melt(ignore_index=False)\n",
    "\n",
    "# Remove self-correlation\n",
    "mask = cov.index != cov['variable']\n",
    "cov = cov[mask]\n",
    "\n",
    "# Add absolute value\n",
    "cov['abs_value'] = np.abs(cov['value'])\n",
    "\n",
    "# Add R-squared\n",
    "cov['r-squared'] = cov['value'] ** 2\n",
    "\n",
    "# Sort by absolute covariance\n",
    "cov.sort_values('abs_value', inplace=True, ascending=False)\n",
    "\n",
    "# Round to four decimal places\n",
    "cov = cov.round(4)\n",
    "\n",
    "# Remove duplicate pairs of features\n",
    "result = []\n",
    "for index, values in cov.iterrows():\n",
    "    combination = [index, values['variable']]\n",
    "    combination.sort()\n",
    "    string = combination[0] + \"-\" + combination[1]\n",
    "    result.append(string)\n",
    "cov['pair'] = result\n",
    "cov.sort_values('pair', inplace=True)\n",
    "cov.drop_duplicates(subset=['pair'], inplace=True)\n",
    "cov.drop('pair', axis=1, inplace=True)\n",
    "\n",
    "# Sort by r-squared\n",
    "cov.sort_values('r-squared', ascending=False, inplace=True)\n",
    "\n",
    "# Display\n",
    "cov[['variable', 'r-squared']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('samuel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b368e36a85415766688ec72e3e874a4b525584eabf4bf7122952a4e0fd64fcde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
