{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28d7344-7e4a-4a28-bf35-a86211b7bf7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate subest SHAP values for the 10k cohort patients\n",
    "\n",
    "## Plain English summary\n",
    "\n",
    "We will create a \"subgroup SHAP value\" for each feature. The 10 features in the model can be classified as either those that are describing the patients characteristics (the “patient descriptive features”) or those that are describing the hospital’s processes (the “hospital descriptive features”). There are eight patient descriptive features (age, stroke severity, prior disability, onset-to-arrival time, stroke type, type of onset time, anticoagulants, and onset during sleep) and there are two hospital descriptive features (arrival-to-scan time, and hospital attended). For this analysis, we only included the single one-hot encoded feature for the attended hospital (and did not include the other 131 one-hot encoded features for the unattended hospitals). We calculated the subgroup SHAP value for each feature by only including the components of it's SHAP value that exclusively contain the effect from the features in the same subgroup. This is expressed as the sum of the main effect and the interaction effects with the other features within it’s subgroup. For the feature “arrival to scan”, which is part of the hospital descriptive subgroup, its refined SHAP value is the main effect plus the interaction with the feature hospital attended. For each of the features in the patient descriptive subgroup, its refined SHAP value is the main effect plus the sum of the interactions with each of the other seven patient descriptive features. For each set of descriptive features (hospital and patient) we fitted a multiple regression to predict the hospitals observed thrombolysis rate from the median refined SHAP value of each feature for patients attending each hospital (using values from the all data model).\n",
    "\n",
    "\n",
    "Create a file with 5 columns () and save it\n",
    "\n",
    "## Model and data\n",
    "\n",
    "An XGBoost model is trained on all but a 10k patient cohort, to predict which patient will recieve thrombolysis.The 10k patient cohort is then used in two ways: 1) as the test set for the model fitting process 2) as a common set of patients that are sent to each hospital in turn to obtain a thrombolysis rate that is comparable across hosptials which has any patient factors removed.\n",
    "\n",
    "The XGBoost model is fitted to all but 10k instances, and uses 10 features: \n",
    "\n",
    "* Arrival-to-scan time: Time from arrival at hospital to scan (mins)\n",
    "* Infarction: Stroke type (1 = infarction, 0 = haemorrhage)\n",
    "* Stroke severity: Stroke severity (NIHSS) on arrival\n",
    "* Precise onset time: Onset time type (1 = precise, 0 = best estimate)\n",
    "* Prior disability level: Disability level (modified Rankin Scale) before stroke\n",
    "* Stroke team: Stroke team attended\n",
    "* Use of AF anticoagulents: Use of atrial fibrillation anticoagulant (1 = Yes, 0 = No)\n",
    "* Onset-to-arrival time: Time from onset of stroke to arrival at hospital (mins)\n",
    "* Onset during sleep: Did stroke occur in sleep?\n",
    "* Age: Age (as middle of 5 year age bands)\n",
    "\n",
    "And one target feature:\n",
    "* Thrombolysis: Recieve thrombolysis (1 = Yes, 0 = No)\n",
    "\n",
    "The 10 features included in the model (to predict whether a patient will recieve thrombolysis) were chosen sequentially as having the single best improvement in model performance (using the ROC AUC). The stroke team feature is included as a one-hot encoded feature.\n",
    "\n",
    "## Aims:\n",
    "\n",
    "* Train XGBoost model on all data except for a 10k set of patients\n",
    "* Predict use of thrombolysis in the heldback 10k cohort of patients at their attended hosptial\n",
    "* Calculate the \"subset SHAP values\" for each feature\n",
    "\n",
    "For each patient provide:\n",
    "* Clinical subset SHAP (total)\n",
    "* Hospital subset SHAP (total)\n",
    "* Hospital main SHAP alone\n",
    "* Total SHAP\n",
    "\n",
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad56ee2-06be-433d-b5f6-49639e8dbafb",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6daa1e72-cd0b-4035-be66-43a234ddca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import copy\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from os.path import exists\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107c937-7e71-4c5f-9c9f-d43612f83fe4",
   "metadata": {},
   "source": [
    "## Set filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e36a656-c5e5-47b4-854f-3882ed983bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model type (used in file save, e.g. xgb_combined_calibrated_oversampled)\n",
    "number_key_features = 10\n",
    "model_text = f'xgb_{number_key_features}_features_10k_cohort'\n",
    "notebook = '04c'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fb027-f0e9-4d50-aae9-ab12343820a0",
   "metadata": {},
   "source": [
    "## Create output folders if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37755327-1974-4049-9db8-e1dd16c43cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './saved_models'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "path = './output'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "path = './predictions'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f0fca-1c28-4fd9-af0a-cf9a4f4a80cf",
   "metadata": {},
   "source": [
    "## Read in JSON file\n",
    "\n",
    "Contains a dictionary for plain English feature names for the 8 features selected in the model. Use these as the column titles in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f816489-2187-47ba-99f7-3a8f386bdc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./output/01_feature_name_dict.json\") as json_file:\n",
    "    dict_feature_name = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94556518-b8e0-4f97-b3bf-57bcea8e391a",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "10k cohort of patients in test data, rest in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a38967eb-956c-4023-8fe9-02d186ee771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../data/10k_training_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "094e69f6-3897-4da4-a838-fabe0b9baaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(data_loc + 'cohort_10000_train.csv')\n",
    "test = pd.read_csv(data_loc + 'cohort_10000_test.csv')\n",
    "\n",
    "# Read in the names of the selected features for the model\n",
    "number_of_features_to_use = 10\n",
    "key_features = pd.read_csv('./output/01_feature_selection.csv')\n",
    "key_features = list(key_features['feature'])[:number_of_features_to_use]\n",
    "# And add the target feature name: S2Thrombolysis\n",
    "key_features.append('S2Thrombolysis')\n",
    "\n",
    "# Select features\n",
    "train = train[key_features]\n",
    "train.rename(columns=dict_feature_name, inplace=True)\n",
    "test = test[key_features]\n",
    "test.rename(columns=dict_feature_name, inplace=True)\n",
    "\n",
    "# KP DO WE NEED THESE?\n",
    "# Save train and test stroke team column\n",
    "#train_stroke_team_ivt = train[['Stroke team', 'Thrombolysis']]\n",
    "#test_stroke_team_ivt = test[['Stroke team', 'Thrombolysis']]\n",
    "#all_data_stroke_team_ivt = pd.concat([test_stroke_team_ivt, train_stroke_team_ivt], axis=0)\n",
    "#all_data_stroke_team_ivt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33bb247-b000-48dd-9c08-84c250c04728",
   "metadata": {},
   "source": [
    "Store list of unique stroke teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59f0275b-03c2-4226-9679-09ed7eec64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals = list(set(train['Stroke team']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ddbfd-692e-4447-99f6-927c4b542e3d",
   "metadata": {},
   "source": [
    "Store list of attended hospital (one per patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8097aac-8e61-4acd-8191-590035d32930",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stroke_team = test['Stroke team']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4512b-d282-4874-bfcc-67d0aed4b472",
   "metadata": {},
   "source": [
    "## Fit XGBoost model\n",
    "\n",
    "Fit or read in XGBoost model on the 10k cohort train/test dataset, and calculate model accuracy.\n",
    "\n",
    "Save models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41f585ce-8199-4523-a9bc-47c6e259b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "# Fit models (True), or load models (False)\n",
    "#fit_models = False#True\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('Thrombolysis', axis=1)\n",
    "X_test = test.drop('Thrombolysis', axis=1)\n",
    "y_train = train['Thrombolysis']\n",
    "y_test = test['Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['Stroke team'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "#X_train_stroke_team = X_train['Stroke team']\n",
    "X_train.drop('Stroke team', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['Stroke team'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "#X_test_stroke_team = X_test['Stroke team']\n",
    "X_test.drop('Stroke team', axis=1, inplace=True)    \n",
    "\n",
    "filename = (f'./saved_models/04_{model_text}.p')\n",
    "file_exists = exists(filename)\n",
    "\n",
    "if file_exists:\n",
    "    # Load models\n",
    "    with open(filename, 'rb') as filehandler:\n",
    "        model = pickle.load(filehandler)\n",
    "else:\n",
    "    # Define model\n",
    "    model = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5)\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save using pickle\n",
    "    with open(filename, 'wb') as filehandler:\n",
    "        pickle.dump(model, filehandler)\n",
    "\n",
    "# Get predicted probabilities and class for 10k cohort\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "y_pred = model.predict(X_test)\n",
    "#y_pred = y_prob > 0.5\n",
    "\n",
    "thrombolysis_rate = []\n",
    "thrombolysis_rate.append(y_pred.mean())\n",
    "    \n",
    "# Save predictions\n",
    "single_predictions = []\n",
    "single_predictions.append(y_pred * 1)\n",
    "\n",
    "# Show accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print (f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3735e3-beb5-449e-9dfc-244dbd0017b0",
   "metadata": {},
   "source": [
    "Calculate receiver operating characteristic curve area under curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e1baf80-2c4a-4e7d-9167-1db5b0fa3a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC ACUC: 0.915\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (f'ROC ACUC: {roc_auc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3cd34-8ff5-43d4-9971-03413d007fbe",
   "metadata": {},
   "source": [
    "## SHAP values and SHAP interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728c301-6f96-4569-a435-e2a231681e94",
   "metadata": {},
   "source": [
    "### Get SHAP values\n",
    "\n",
    "Either set up method to estimate SHAP values, or if already created then load from pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97ae24b0-3f69-4e04-b52e-ed7af0b8b80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 ms, sys: 0 ns, total: 23.9 ms\n",
      "Wall time: 22.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set up method to estimate SHAP values for tree models and ensembles of trees\n",
    "filename = (f'./output/04_{model_text}_shap_explainer_'\n",
    "            f'object.p')\n",
    "file_exists = exists(filename)\n",
    "\n",
    "if file_exists:\n",
    "    # Load SHAP explainer\n",
    "    with open(filename, 'rb') as filehandler:\n",
    "        explainer = pickle.load(filehandler)\n",
    "else:\n",
    "    # Get SHAP explainer (using the model and feature values from training set)\n",
    "    explainer = shap.TreeExplainer(model, X_train)\n",
    "    # Save using pickle\n",
    "    with open(filename, 'wb') as filehandler:\n",
    "        pickle.dump(explainer, filehandler)\n",
    "\n",
    "## Repeat for SHAP explainer with probabilities\n",
    "#filename = (f'./output/04_{model_text}_shap_explainer_probability_'\n",
    "#            f'object.p')\n",
    "#file_exists = exists(filename)\n",
    "#\n",
    "#if file_exists:\n",
    "#    # Load SHAP explainer\n",
    "#    with open(filename, 'rb') as filehandler:\n",
    "#        explainer = pickle.load(filehandler)\n",
    "#else:\n",
    "#    # Get SHAP explainer (using the model and feature values from training set)\n",
    "#    # This is not used in this notebook but is saved for other notebooks to use\n",
    "#    explainer_probability = shap.TreeExplainer(model, X_train, model_output='probability')\n",
    "#    # Save using pickle\n",
    "#    with open(filename, 'wb') as filehandler:\n",
    "#        pickle.dump(explainer_probability, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8ca1a-f530-4444-8d36-a5a5b869321a",
   "metadata": {},
   "source": [
    "Use this to calculate the SHAP values for the 10k cohort going to their actual hospital (in notebook 04 the 10k cohort were all sent to each of the 132 hospitals - this notebook is different)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4e58497-3b25-4fe7-a11e-15612cda4199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 ms, sys: 7.72 ms, total: 9.1 ms\n",
      "Wall time: 7.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use method to estimate SHAP values for tree models and ensembles of trees\n",
    "filename = (f'./output/{notebook}_{model_text}_shap_values.p')\n",
    "file_exists = exists(filename)\n",
    "\n",
    "if file_exists:\n",
    "    # Load SHAP values\n",
    "    with open(filename, 'rb') as filehandler:\n",
    "        shap_values_extended = pickle.load(filehandler)\n",
    "else:\n",
    "    # Get SHAP values (using the explainer and feature values from 10k cohort)\n",
    "    shap_values_extended = explainer(X_test)\n",
    "    # Save using pickle\n",
    "    with open(filename, 'wb') as filehandler:\n",
    "        pickle.dump(shap_values_extended, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6e093-71f5-445b-9549-4f0885f47854",
   "metadata": {},
   "source": [
    "#### Format the SHAP values data\n",
    "\n",
    "Features are in the same order in shap_values_extended as they are in the original dataset.\n",
    "\n",
    "Use this fact to extract the SHAP values for just the one-hot encoded hospital feature of the attended hospital per patient (along with the SHAP values for the other features). \n",
    "\n",
    "Create a dataframe containing the SHAP values: an instance per row, and a SHAP value for each feature (with the hosptial feature being the attended hospital's one-hot encoded feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3811c3c-68f7-4d07-9244-d2ab2ab5c893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Precise onset time',\n",
       " 'Onset during sleep',\n",
       " 'Infarction',\n",
       " 'Age',\n",
       " 'Prior disability level',\n",
       " 'Use of AF anticoagulants',\n",
       " 'Onset-to-arrival time',\n",
       " 'Stroke severity',\n",
       " 'Arrival-to-scan time',\n",
       " 'Attended stroke team']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save\n",
    "#filename = f'./output/{notebook}_{model_text}_SHAP_values.csv'\n",
    "#file_exists = exists(filename)\n",
    "\n",
    "#if file_exists:\n",
    "#    df_hosp_shap_values = pd.read_csv(filename)\n",
    "#else:\n",
    "\n",
    "# Get list of hospital one hot encoded column titles\n",
    "hospitals_ohe = X_test.filter(regex='^team',axis=1).columns\n",
    "n_hospitals = len(hospitals_ohe)\n",
    "# Create list of column index for these hospital column titles\n",
    "hospital_columns_index = [X_test.columns.get_loc(col) for col in hospitals_ohe]\n",
    "\n",
    "# Get list of features not one hot encoded hospital column titles\n",
    "features_not_hospitals_ohe = list(set(X_test.columns) - set(hospitals_ohe))\n",
    "# Create list of column index for these feature column titles\n",
    "features_not_hospitals_ohe_columns_index = (\n",
    "    [X_test.columns.get_loc(col) for col in features_not_hospitals_ohe])\n",
    "\n",
    "# Create column titles\n",
    "columns = copy.deepcopy(features_not_hospitals_ohe)\n",
    "columns.append(\"Attended stroke team\")\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "392a8fbb-7cfa-48d2-8248-7fab3165d3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precise onset time</th>\n",
       "      <th>Onset during sleep</th>\n",
       "      <th>Infarction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Prior disability level</th>\n",
       "      <th>Use of AF anticoagulants</th>\n",
       "      <th>Onset-to-arrival time</th>\n",
       "      <th>Stroke severity</th>\n",
       "      <th>Arrival-to-scan time</th>\n",
       "      <th>Attended stroke team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.301728</td>\n",
       "      <td>0.026165</td>\n",
       "      <td>-7.214427</td>\n",
       "      <td>-0.040446</td>\n",
       "      <td>0.224214</td>\n",
       "      <td>-0.84298</td>\n",
       "      <td>0.316521</td>\n",
       "      <td>0.23448</td>\n",
       "      <td>0.497258</td>\n",
       "      <td>0.017261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.521458</td>\n",
       "      <td>-1.757024</td>\n",
       "      <td>0.811219</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>-0.168006</td>\n",
       "      <td>-1.204795</td>\n",
       "      <td>0.158561</td>\n",
       "      <td>-1.30463</td>\n",
       "      <td>0.339406</td>\n",
       "      <td>-0.618299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.411153</td>\n",
       "      <td>-1.785861</td>\n",
       "      <td>1.014213</td>\n",
       "      <td>0.107648</td>\n",
       "      <td>-0.538457</td>\n",
       "      <td>0.108413</td>\n",
       "      <td>0.151406</td>\n",
       "      <td>1.161219</td>\n",
       "      <td>1.418404</td>\n",
       "      <td>0.121969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788107</td>\n",
       "      <td>0.038205</td>\n",
       "      <td>1.208424</td>\n",
       "      <td>0.085075</td>\n",
       "      <td>0.575384</td>\n",
       "      <td>0.14374</td>\n",
       "      <td>0.182026</td>\n",
       "      <td>0.392636</td>\n",
       "      <td>1.356363</td>\n",
       "      <td>1.148519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.710574</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.966015</td>\n",
       "      <td>-0.043217</td>\n",
       "      <td>-0.897133</td>\n",
       "      <td>-1.373795</td>\n",
       "      <td>0.621658</td>\n",
       "      <td>0.906334</td>\n",
       "      <td>1.414243</td>\n",
       "      <td>0.196445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Precise onset time Onset during sleep Infarction       Age  \\\n",
       "0          -0.301728           0.026165  -7.214427 -0.040446   \n",
       "0          -1.521458          -1.757024   0.811219  0.004312   \n",
       "0          -0.411153          -1.785861   1.014213  0.107648   \n",
       "0           0.788107           0.038205   1.208424  0.085075   \n",
       "0          -0.710574           0.043243   0.966015 -0.043217   \n",
       "\n",
       "  Prior disability level Use of AF anticoagulants Onset-to-arrival time  \\\n",
       "0               0.224214                 -0.84298              0.316521   \n",
       "0              -0.168006                -1.204795              0.158561   \n",
       "0              -0.538457                 0.108413              0.151406   \n",
       "0               0.575384                  0.14374              0.182026   \n",
       "0              -0.897133                -1.373795              0.621658   \n",
       "\n",
       "  Stroke severity Arrival-to-scan time Attended stroke team  \n",
       "0         0.23448             0.497258             0.017261  \n",
       "0        -1.30463             0.339406            -0.618299  \n",
       "0        1.161219             1.418404             0.121969  \n",
       "0        0.392636             1.356363             1.148519  \n",
       "0        0.906334             1.414243             0.196445  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise empty dataframe with these titles\n",
    "df_shap_values_attended_hosp = pd.DataFrame(columns=columns)\n",
    "\n",
    "# For each patient\n",
    "for row, hosp_attended in zip(shap_values_extended.values,\n",
    "                              test_stroke_team):\n",
    "    \n",
    "    # get column for atteneded hospital\n",
    "    hospital_column_index = [X_test.columns.get_loc(f\"team_{hosp_attended}\")]\n",
    "    \n",
    "#    for hospital in hospitals:\n",
    "#    print (f\"Joining SHAP for hospital {count} of {len(hospitals)}\")\n",
    "    # Get hospital SHAP values extended\n",
    "#    shap_values_extended = dict_shap_values_extended[f\"{hospital}\"]\n",
    "\n",
    "    # Use the index list to access the fatures that aren't hospital shap values (as array)\n",
    "    non_hosp_shap_values = row[features_not_hospitals_ohe_columns_index]\n",
    "    # Use the index list to access the hospital shap values (as array)\n",
    "#    hosp_shap_values = row[hospital_columns_index]\n",
    "    \n",
    "    # Put values for features in dataframe with column title\n",
    "    # Need to put array in dataframe and transpose for it (then convert back to array) to be added as a row (else put it as a column)\n",
    "    df_temp = pd.DataFrame(data=pd.DataFrame(non_hosp_shap_values).T.to_numpy(), \n",
    "                           columns=features_not_hospitals_ohe)\n",
    "\n",
    "    # Store the sum of the SHAP values (for all of the hospital features)\n",
    "#    df_temp[\"All stroke teams\"] = df_temp.sum(axis=1)\n",
    "\n",
    "    # Store which hospital patient went to\n",
    "#    df_temp[\"Stroke team\"] = hospital\n",
    "\n",
    "    # Store the SHAP values for the hospital attended\n",
    "    df_temp[\"Attended stroke team\"] = row[hospital_column_index]\n",
    "   \n",
    "\n",
    "    # Store the sum of the SHAP values for all of the hospitals not attended\n",
    "#    df_temp[\"Not attended stroke teams\"] = (df_temp[\"All stroke teams\"] - \n",
    "#                                            df_temp[\"Attended stroke team\"])\n",
    "\n",
    "    # Add to master DataFrame\n",
    "    df_shap_values_attended_hosp = pd.concat([df_shap_values_attended_hosp, df_temp], axis=0)\n",
    "\n",
    "# View preview\n",
    "df_shap_values_attended_hosp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd7453-eb29-48ce-8167-894b9303f054",
   "metadata": {},
   "source": [
    "Code used to get SHAP interactions. Needed to set up explainer without X_train. Investigate why later. Gave error \"EATURE_DEPENDENCE::independent does not support interactions!\" when included X_train in the explainer. Didn't understand the explanations for this error when I googled it. It was raised as an issue for SHAP library.\n",
    "\n",
    "CODE:\n",
    "\n",
    "explainer = shap.TreeExplainer(model)#, X_train)\n",
    "shap_interaction = explainer.shap_interaction_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821501e-37b4-44f6-a744-5b7e40334b34",
   "metadata": {},
   "source": [
    "### Get SHAP interaction values\n",
    "Use the TreeExplainer to also calculate the SHAP main effect and SHAP interaction values (the sum of which give the SHAP values for each feature)\n",
    "\n",
    "A SHAP interaction value is returned for each pair of features (including with itself, which is known as the main effect), for each instance. The SHAP value for a feature is the sum of it's pair-wise feature interactions.\n",
    "\n",
    "Use these values to access the main effect for each of the one-hot encoded hospital features.\n",
    "\n",
    "Either load from pickle (if file exists), or calculate.\n",
    "\n",
    "#### At the same tiume: Format the SHAP interaction data so only get the main effect for the hospital features\n",
    "\n",
    "Features are in the same order in shap_interaction as they are in the original dataset.\n",
    "\n",
    "Use this fact to extract the SHAP main effect values for the one-hot encoded hospital features. Create a dataframe containing the SHAP values: an instance per row, and a one-hot encoded hospital feature per column.\n",
    "\n",
    "Also include a column containing the Stroke team that each instance attended.\n",
    "\n",
    "And three further columns:\n",
    "1. contribution from all the hospital features\n",
    "2. contribution from attending the hospital\n",
    "3. contribution from not attending the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02d75c-606e-4ea7-b808-8a783fbc860e",
   "metadata": {},
   "source": [
    "SHAP interaction values have a matrix of values (per pair of features) per instance.\n",
    "\n",
    "For each hospital, have the 10k instances each with a 139x139 matrix of SHAP interaction values (with the SHAP main effect on the diagonal positions).\n",
    "\n",
    "Once get the SHAP interaction values, calculate the subset SHAP values. This is the main effect + interactions with the features int he same subset (hospital, or patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "991890c3-6181-4333-879f-efd8dc2956ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 54s, sys: 8min 19s, total: 1h 9min 13s\n",
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "filename = f'./output/{notebook}_{model_text}_shap_interaction_array.p'\n",
    "file_exists = exists(filename)\n",
    "\n",
    "if file_exists:\n",
    "    # Load SHAP interaction array\n",
    "    with open(filename, 'rb') as filehandler:\n",
    "        shap_interactions = pickle.load(filehandler)\n",
    "else:\n",
    "    explainer = shap.TreeExplainer(model)#, X_train)\n",
    "\n",
    "    # Get SHAP values (along with base and feature values)\n",
    "    shap_interactions = explainer.shap_interaction_values(X_test)\n",
    "\n",
    "    # Save using pickle\n",
    "    with open(filename, 'wb') as filehandler:\n",
    "        pickle.dump(shap_interactions, filehandler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2120d252-b8b3-4662-af00-39ad6b32756e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arrival-to-scan time',\n",
       " 'Infarction',\n",
       " 'Stroke severity',\n",
       " 'Precise onset time',\n",
       " 'Prior disability level',\n",
       " 'Use of AF anticoagulants',\n",
       " 'Onset-to-arrival time',\n",
       " 'Onset during sleep',\n",
       " 'Age',\n",
       " 'team_AGNOF1041H']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = list(X_test.columns)\n",
    "col_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a3411-2df1-4071-b73b-7289c7da445e",
   "metadata": {},
   "source": [
    "### Define the features in each subset\n",
    "\n",
    "Have two subsets: patient and hosptial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3b91b700-c9a7-46f7-875f-4b97d27e61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_features = ['Infarction','Stroke severity',\n",
    "                    'Precise onset time','Prior disability level',\n",
    "                    'Use of AF anticoagulants','Onset-to-arrival time',\n",
    "                    'Onset during sleep','Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "44b2ca36-021b-45b9-9051-2b5b6bd32be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_features = ['Arrival-to-scan time','Stroke team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "00cb95bf-c445-4b0e-8012-4423eaf24c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.67 s, sys: 37.8 ms, total: 3.7 s\n",
      "Wall time: 3.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get indices for the hospitals\n",
    "hospitals_indices = [col_names.index(h) for h in hospitals_ohe]\n",
    "\n",
    "# create list (one per value type) with features as column title\n",
    "shap_values_without_unattended_hosp = []\n",
    "shap_main_effects = []\n",
    "shap_interactions_within_subgroup = []\n",
    "shap_interactions_across_subgroups = []\n",
    "shap_main_effects_and_within_interactions = []\n",
    "\n",
    "# work through each patients shap interaction matrix\n",
    "for p in range(shap_interactions.shape[0]):\n",
    "\n",
    "    # get shap interactions for a patient\n",
    "    si = shap_interactions[p]\n",
    "\n",
    "    # get hospital the patient attends\n",
    "    attend = test_stroke_team[p]\n",
    "    \n",
    "    # get column index for hosptial attend\n",
    "    hospital_keep_index = [col_names.index(f'team_{attend}')]\n",
    "\n",
    "    # get indices for the other hosptials (those not attend) to remove for \n",
    "    #   this patient\n",
    "    hospitals_remove_indices = list(set(hospitals_indices) - \n",
    "                                    set(hospital_keep_index))\n",
    "    \n",
    "    # delete the rows and columns in the shap interaction matrix for the \n",
    "    #   hospitals not attended\n",
    "    shap_interaction_attendhosp = np.delete(si, hospitals_remove_indices, 0)\n",
    "    shap_interaction_attendhosp = np.delete(shap_interaction_attendhosp, \n",
    "                                            hospitals_remove_indices, 1)\n",
    "\n",
    "    # and remove the not attended hospitals from the column names\n",
    "    col_names_attendhosp = np.delete(col_names, hospitals_remove_indices, 0)\n",
    "\n",
    "    # rename the one hosptial left with the generic \"Stroke team\" name\n",
    "    col_names_attendhosp = np.char.replace(col_names_attendhosp, \n",
    "                                           f'team_{attend}', \"Stroke team\")\n",
    "    \n",
    "    # number of features in the resulting shap interaction matrix\n",
    "    n_si_features = shap_interaction_attendhosp.shape[0]\n",
    "\n",
    "    # get the indices for the features in each multiple regression\n",
    "    patient_features_col_id = [np.where(col_names_attendhosp==f)[0][0] \n",
    "                               for f in patient_features]\n",
    "    hospital_features_col_id = [np.where(col_names_attendhosp==f)[0][0] \n",
    "                                for f in hospital_features]\n",
    "    \n",
    "    # calculate the different feature values\n",
    "    # 1. SHAP values (without any contribution from hospital not attended)\n",
    "    shap_values = shap_interaction_attendhosp.sum(axis=1)\n",
    "\n",
    "    # add to list (entry per patient containing value per feature)\n",
    "    shap_values_without_unattended_hosp.append(shap_values)\n",
    "\n",
    "    # 2. main effect value for each of the features\n",
    "    main_effects = np.diagonal(shap_interaction_attendhosp)\n",
    "\n",
    "    # add to list (entry per patient contianing value per feature)\n",
    "    shap_main_effects.append(main_effects)\n",
    "    \n",
    "    # 3. SHAP interactions within feature subgroup (patient, hospital)\n",
    "    list_of_list = [patient_features_col_id,\n",
    "                    hospital_features_col_id]\n",
    "\n",
    "    # initialise a zero array with size of number of features (excluding \n",
    "    #   unattended hostpial)\n",
    "    within_subgroup_array = np.zeros((n_si_features))\n",
    "    # Through a list of subgroup features at a time\n",
    "    for features_col_ids in list_of_list: \n",
    "        # Through features in subgroup\n",
    "        for f1 in features_col_ids:\n",
    "            # Take a deep copy of all of the features\n",
    "            remaining = copy.deepcopy(features_col_ids)\n",
    "            # Remove the current feature (get a list of the other features in \n",
    "            #   the subgroup\n",
    "            remaining.remove(f1)\n",
    "            # Initialise a variable to sum the interactions that are with\n",
    "            #   features from the same subgroup\n",
    "            sum_elements = 0\n",
    "            # Through the other features in the subgroup\n",
    "            for f2 in remaining:\n",
    "                sum_elements += shap_interaction_attendhosp[f1, f2]\n",
    "            # Store summed interactions in the array\n",
    "            within_subgroup_array[f1] = sum_elements\n",
    "    \n",
    "    # add to list (entry per patient contianing value per feature)\n",
    "    shap_interactions_within_subgroup.append(within_subgroup_array)\n",
    "    \n",
    "    # 4. SHAP interactions outside feature subgroup\n",
    "    across_subgroups_array = np.zeros((n_si_features))\n",
    "\n",
    "    # Through patient subgroup features\n",
    "    for f1 in patient_features_col_id:\n",
    "        # Initialise variable to sum the interactions that are with\n",
    "        #   features from the different subgroup\n",
    "        sum_elements = 0\n",
    "        # Through the features in the other subgroup\n",
    "        for f2 in hospital_features_col_id:\n",
    "            sum_elements += shap_interaction_attendhosp[f1, f2]\n",
    "        # Store summed interactions in the array\n",
    "        across_subgroups_array[f1] = sum_elements\n",
    "\n",
    "    # Through patient subgroup features\n",
    "    for f1 in hospital_features_col_id:\n",
    "        # Initialise variable to sum the interactions that are with\n",
    "        #   features from the different subgroup\n",
    "        sum_elements = 0\n",
    "        # Through the features in the other subgroup\n",
    "        for f2 in patient_features_col_id:\n",
    "            sum_elements += shap_interaction_attendhosp[f1, f2]\n",
    "        # Store summed interactions in the array\n",
    "        across_subgroups_array[f1] = sum_elements\n",
    "\n",
    "    # add to list (entry per patient contianing value per feature)\n",
    "    shap_interactions_across_subgroups.append(across_subgroups_array)\n",
    "\n",
    "    # 5. main effect + SHAP interaction within: sum array (2) + (3)\n",
    "    main_effect_and_within = main_effects + within_subgroup_array\n",
    "    \n",
    "    # add to list (entry per patient contianing value per feature)\n",
    "    shap_main_effects_and_within_interactions.append(main_effect_and_within)\n",
    "    \n",
    "# put lists into dataframe, with features as column title\n",
    "df_hosp_shap_values_without_unattended_hosp = (\n",
    "                        pd.DataFrame(shap_values_without_unattended_hosp, \n",
    "                                     columns=col_names_attendhosp))\n",
    "df_hosp_shap_main_effects = (\n",
    "                        pd.DataFrame(shap_main_effects, \n",
    "                                     columns=col_names_attendhosp))\n",
    "df_hosp_shap_interactions_within = (\n",
    "                        pd.DataFrame(shap_interactions_within_subgroup, \n",
    "                                     columns=col_names_attendhosp))\n",
    "df_hosp_shap_interactions_outside = (\n",
    "                        pd.DataFrame(shap_interactions_across_subgroups, \n",
    "                                     columns=col_names_attendhosp))\n",
    "df_hosp_shap_main_effects_and_within_interactions = (\n",
    "                        pd.DataFrame(shap_main_effects_and_within_interactions, \n",
    "                                     columns=col_names_attendhosp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "201a8750-d2ca-4c48-a500-895c3dab0d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrival-to-scan time</th>\n",
       "      <th>Infarction</th>\n",
       "      <th>Stroke severity</th>\n",
       "      <th>Precise onset time</th>\n",
       "      <th>Prior disability level</th>\n",
       "      <th>Use of AF anticoagulants</th>\n",
       "      <th>Onset-to-arrival time</th>\n",
       "      <th>Onset during sleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>Stroke team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344768</td>\n",
       "      <td>-8.024301</td>\n",
       "      <td>-0.143781</td>\n",
       "      <td>-0.443354</td>\n",
       "      <td>0.180350</td>\n",
       "      <td>-0.795312</td>\n",
       "      <td>0.198188</td>\n",
       "      <td>0.034327</td>\n",
       "      <td>-0.012963</td>\n",
       "      <td>-0.148998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.146492</td>\n",
       "      <td>0.180547</td>\n",
       "      <td>-1.639628</td>\n",
       "      <td>-0.867942</td>\n",
       "      <td>-0.407695</td>\n",
       "      <td>-1.185268</td>\n",
       "      <td>0.084938</td>\n",
       "      <td>-1.406218</td>\n",
       "      <td>-0.022495</td>\n",
       "      <td>0.266283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869757</td>\n",
       "      <td>0.297213</td>\n",
       "      <td>0.786024</td>\n",
       "      <td>-0.949098</td>\n",
       "      <td>-0.611850</td>\n",
       "      <td>0.151533</td>\n",
       "      <td>-0.030462</td>\n",
       "      <td>-1.601547</td>\n",
       "      <td>0.116776</td>\n",
       "      <td>-0.292496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.883030</td>\n",
       "      <td>0.434410</td>\n",
       "      <td>0.201015</td>\n",
       "      <td>0.469563</td>\n",
       "      <td>0.414798</td>\n",
       "      <td>0.185233</td>\n",
       "      <td>0.121663</td>\n",
       "      <td>0.039728</td>\n",
       "      <td>0.063495</td>\n",
       "      <td>0.902912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883407</td>\n",
       "      <td>0.239610</td>\n",
       "      <td>0.455630</td>\n",
       "      <td>-0.762424</td>\n",
       "      <td>-0.778811</td>\n",
       "      <td>-1.276674</td>\n",
       "      <td>0.438555</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>-0.170120</td>\n",
       "      <td>0.005039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.857083</td>\n",
       "      <td>0.214481</td>\n",
       "      <td>-0.298851</td>\n",
       "      <td>-0.805878</td>\n",
       "      <td>-0.458450</td>\n",
       "      <td>-1.594497</td>\n",
       "      <td>-0.409960</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>-0.424924</td>\n",
       "      <td>-0.671811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.037697</td>\n",
       "      <td>0.219542</td>\n",
       "      <td>-2.275019</td>\n",
       "      <td>-0.609995</td>\n",
       "      <td>0.320527</td>\n",
       "      <td>0.145350</td>\n",
       "      <td>0.053685</td>\n",
       "      <td>0.047866</td>\n",
       "      <td>0.131290</td>\n",
       "      <td>-0.945354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.000820</td>\n",
       "      <td>0.372444</td>\n",
       "      <td>0.739026</td>\n",
       "      <td>-0.959546</td>\n",
       "      <td>0.423563</td>\n",
       "      <td>0.161873</td>\n",
       "      <td>0.025115</td>\n",
       "      <td>0.082223</td>\n",
       "      <td>0.130244</td>\n",
       "      <td>0.958532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.650933</td>\n",
       "      <td>0.269002</td>\n",
       "      <td>-1.765828</td>\n",
       "      <td>0.372576</td>\n",
       "      <td>0.315834</td>\n",
       "      <td>0.124963</td>\n",
       "      <td>-0.015693</td>\n",
       "      <td>0.037125</td>\n",
       "      <td>0.167809</td>\n",
       "      <td>0.047880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.793947</td>\n",
       "      <td>0.375587</td>\n",
       "      <td>0.040653</td>\n",
       "      <td>0.459704</td>\n",
       "      <td>-0.308645</td>\n",
       "      <td>0.182024</td>\n",
       "      <td>-0.186369</td>\n",
       "      <td>0.036670</td>\n",
       "      <td>-0.141659</td>\n",
       "      <td>-0.522043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Arrival-to-scan time  Infarction  Stroke severity  Precise onset time  \\\n",
       "0                 0.344768   -8.024301        -0.143781           -0.443354   \n",
       "1                -0.146492    0.180547        -1.639628           -0.867942   \n",
       "2                 0.869757    0.297213         0.786024           -0.949098   \n",
       "3                 0.883030    0.434410         0.201015            0.469563   \n",
       "4                 0.883407    0.239610         0.455630           -0.762424   \n",
       "...                    ...         ...              ...                 ...   \n",
       "9995              0.857083    0.214481        -0.298851           -0.805878   \n",
       "9996              0.037697    0.219542        -2.275019           -0.609995   \n",
       "9997              1.000820    0.372444         0.739026           -0.959546   \n",
       "9998              0.650933    0.269002        -1.765828            0.372576   \n",
       "9999              0.793947    0.375587         0.040653            0.459704   \n",
       "\n",
       "      Prior disability level  Use of AF anticoagulants  Onset-to-arrival time  \\\n",
       "0                   0.180350                 -0.795312               0.198188   \n",
       "1                  -0.407695                 -1.185268               0.084938   \n",
       "2                  -0.611850                  0.151533              -0.030462   \n",
       "3                   0.414798                  0.185233               0.121663   \n",
       "4                  -0.778811                 -1.276674               0.438555   \n",
       "...                      ...                       ...                    ...   \n",
       "9995               -0.458450                 -1.594497              -0.409960   \n",
       "9996                0.320527                  0.145350               0.053685   \n",
       "9997                0.423563                  0.161873               0.025115   \n",
       "9998                0.315834                  0.124963              -0.015693   \n",
       "9999               -0.308645                  0.182024              -0.186369   \n",
       "\n",
       "      Onset during sleep       Age  Stroke team  \n",
       "0               0.034327 -0.012963    -0.148998  \n",
       "1              -1.406218 -0.022495     0.266283  \n",
       "2              -1.601547  0.116776    -0.292496  \n",
       "3               0.039728  0.063495     0.902912  \n",
       "4               0.052786 -0.170120     0.005039  \n",
       "...                  ...       ...          ...  \n",
       "9995            0.045033 -0.424924    -0.671811  \n",
       "9996            0.047866  0.131290    -0.945354  \n",
       "9997            0.082223  0.130244     0.958532  \n",
       "9998            0.037125  0.167809     0.047880  \n",
       "9999            0.036670 -0.141659    -0.522043  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hosp_shap_main_effects_and_within_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ba6a7a8-9ffe-47f0-9370-8d2a8085a66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arrival-to-scan time', 'Infarction', 'Stroke severity',\n",
       "       'Precise onset time', 'Prior disability level',\n",
       "       'Use of AF anticoagulants', 'Onset-to-arrival time',\n",
       "       'Onset during sleep', 'Age', 'Stroke team'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hosp_shap_main_effects_and_within_interactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "803afe82-6af2-4cf6-b6e7-ea79eac085b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_subset_total</th>\n",
       "      <th>hospital_subset_total</th>\n",
       "      <th>hospital_main_shap</th>\n",
       "      <th>total_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.006844</td>\n",
       "      <td>0.195771</td>\n",
       "      <td>-0.150145</td>\n",
       "      <td>-7.111710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.263762</td>\n",
       "      <td>0.119791</td>\n",
       "      <td>0.266337</td>\n",
       "      <td>-5.373571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.841411</td>\n",
       "      <td>0.577261</td>\n",
       "      <td>-0.386164</td>\n",
       "      <td>1.244765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.929906</td>\n",
       "      <td>1.785942</td>\n",
       "      <td>0.870760</td>\n",
       "      <td>5.908253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.801448</td>\n",
       "      <td>0.888446</td>\n",
       "      <td>0.053796</td>\n",
       "      <td>1.020495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_subset_total  hospital_subset_total  hospital_main_shap  total_shap\n",
       "0             -9.006844               0.195771           -0.150145   -7.111710\n",
       "1             -5.263762               0.119791            0.266337   -5.373571\n",
       "2             -1.841411               0.577261           -0.386164    1.244765\n",
       "3              1.929906               1.785942            0.870760    5.908253\n",
       "4             -1.801448               0.888446            0.053796    1.020495"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of column index for the two subset of features\n",
    "#patient_feature_column_index = [df_hosp_shap_main_effects_and_within_interactions.columns.get_loc(col) for col in patient_features]\n",
    "#hospital_feature_column_index = [df_hosp_shap_main_effects_and_within_interactions.columns.get_loc(col) for col in hospital_features]\n",
    "\n",
    "df_SHAP_output = pd.DataFrame()\n",
    "\n",
    "# Clinical subset SHAP (total)\n",
    "df_SHAP_output[\"patient_subset_total\"] = (\n",
    " df_hosp_shap_main_effects_and_within_interactions[patient_features].sum(axis=1))\n",
    "\n",
    "# Hospital subset SHAP (total)\n",
    "df_SHAP_output[\"hospital_subset_total\"] = (\n",
    " df_hosp_shap_main_effects_and_within_interactions[hospital_features].sum(axis=1))\n",
    "\n",
    "# Hospital main SHAP alone\n",
    "df_SHAP_output[\"hospital_main_shap\"] = (df_hosp_shap_main_effects[\"Stroke team\"])\n",
    " \n",
    "# Total SHAP\n",
    "df_SHAP_output[\"total_shap\"] = shap_values_extended.values.sum(axis=1)\n",
    "\n",
    "df_SHAP_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "994230bd-cae0-4616-9916-d5cb5e8635e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'./output/{notebook}_{model_text}_subset_shap_values.csv'\n",
    "df_SHAP_output.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952a906-0a1f-4e36-b822-b18679dd04b1",
   "metadata": {},
   "source": [
    "Check the SHAP equals the y_prob. \n",
    "\n",
    "# NOT QUITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b7fe8534-8d99-40ac-b0ad-8c5426fb3a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.2879346e-05, 2.4379473e-04, 1.5438652e-01, ..., 9.1904640e-01,\n",
       "       2.4417993e-01, 5.5574960e-01], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e5a4d29c-19f0-4ff1-b681-92997ea8b45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.28811736e-05, 2.43854477e-04, 1.82573368e-01, ...,\n",
       "       1.13527551e+01, 3.23066382e-01, 1.25098272e+00])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(shap_values_extended.values.sum(axis=1) + shap_values_extended.base_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b368e36a85415766688ec72e3e874a4b525584eabf4bf7122952a4e0fd64fcde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
